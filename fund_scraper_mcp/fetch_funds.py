"""
å‘½ä»¤è¡Œå·¥å…· - èŽ·å–åŸºé‡‘æ•°æ®å¹¶ä¿å­˜ä¸º CSV/JSONï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰
ç”¨æ³•ï¼š
  python fetch_funds.py --max 100                    # èŽ·å–å‰100ä¸ªåŸºé‡‘
  python fetch_funds.py --all                        # èŽ·å–æ‰€æœ‰åŸºé‡‘ï¼ˆçº¦26000+ä¸ªï¼Œè€—æ—¶è¾ƒé•¿ï¼‰
  python fetch_funds.py --max 100 --format csv       # ä¿å­˜ä¸º CSV æ ¼å¼
  python fetch_funds.py --max 100 --output my.csv    # æŒ‡å®šè¾“å‡ºæ–‡ä»¶å
  python fetch_funds.py --all --resume               # æ–­ç‚¹ç»­ä¼ ï¼Œä»Žä¸Šæ¬¡ä¸­æ–­å¤„ç»§ç»­
"""
import asyncio
import json
import csv
import sys
import os
import argparse
from datetime import datetime

# è®¾ç½® UTF-8 ç¼–ç ï¼ˆWindows æŽ§åˆ¶å°å…¼å®¹ï¼‰
if sys.platform == 'win32':
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from browser_manager import BrowserManager
from scrapers.eastmoney_scraper import EastmoneyScraper


class IncrementalCSVWriter:
    """å¢žé‡å†™å…¥ CSV çš„å·¥å…·ç±»"""

    def __init__(self, filename):
        self.filename = filename
        self.abs_path = os.path.abspath(filename)
        self.fieldnames = [
            'symbol', 'sname', 'per_nav', 'total_nav', 'yesterday_nav',
            'nav_rate', 'nav_a', 'sg_states', 'nav_date', 'fund_manager',
            'jjlx', 'jjzfe'
        ]
        self.count = 0
        self.file = None
        self.writer = None
        self.is_new_file = not os.path.exists(filename)

    def __enter__(self):
        # å¦‚æžœæ˜¯æ–°æ–‡ä»¶ï¼Œåˆ›å»ºå¹¶å†™å…¥è¡¨å¤´
        if self.is_new_file:
            self.file = open(self.filename, 'w', newline='', encoding='utf-8-sig')
            self.writer = csv.DictWriter(self.file, fieldnames=self.fieldnames, extrasaction='ignore')
            self.writer.writeheader()
            print(f"ðŸ“ åˆ›å»ºæ–°æ–‡ä»¶: {self.abs_path}")
        else:
            # å¦‚æžœæ˜¯å·²å­˜åœ¨çš„æ–‡ä»¶ï¼Œè¿½åŠ æ¨¡å¼æ‰“å¼€
            self.file = open(self.filename, 'a', newline='', encoding='utf-8-sig')
            self.writer = csv.DictWriter(self.file, fieldnames=self.fieldnames, extrasaction='ignore')
            # è¯»å–å·²æœ‰è®°å½•æ•°
            with open(self.filename, 'r', encoding='utf-8-sig') as f:
                self.count = sum(1 for _ in f) - 1  # å‡åŽ»è¡¨å¤´
            print(f"ðŸ“ è¿½åŠ åˆ°å·²æœ‰æ–‡ä»¶: {self.abs_path}")
            print(f"   å·²æœ‰ {self.count} æ¡è®°å½•")

        return self

    def write(self, data):
        """å†™å…¥ä¸€æ¡è®°å½•"""
        self.writer.writerow(data)
        self.file.flush()  # ç«‹å³åˆ·æ–°åˆ°ç£ç›˜
        self.count += 1

    def __exit__(self, exc_type, exc_val, exc_tb):
        if self.file:
            self.file.close()


def load_processed_symbols(filename):
    """ä»Žå·²æœ‰çš„CSVæ–‡ä»¶ä¸­è¯»å–å·²å¤„ç†çš„åŸºé‡‘ä»£ç """
    if not os.path.exists(filename):
        return set()

    processed = set()
    try:
        with open(filename, 'r', encoding='utf-8-sig') as f:
            reader = csv.DictReader(f)
            for row in reader:
                if row.get('symbol'):
                    processed.add(row['symbol'])
    except Exception as e:
        print(f"âš ï¸ è¯»å–å·²æœ‰æ–‡ä»¶å¤±è´¥: {e}")
        return set()

    return processed


async def fetch_funds_incremental(output_file, max_funds=None, batch_size=100, delay=1.0, resume=False):
    """å¢žé‡èŽ·å–åŸºé‡‘æ•°æ®ï¼ˆè¾¹çˆ¬è¾¹å†™ï¼‰"""

    print("=" * 70)
    if max_funds:
        print(f"å¼€å§‹èŽ·å–å‰ {max_funds} ä¸ªåŸºé‡‘æ•°æ®...")
    else:
        print("å¼€å§‹èŽ·å–æ‰€æœ‰åŸºé‡‘æ•°æ®ï¼ˆçº¦26000+ä¸ªï¼Œé¢„è®¡éœ€è¦æ•°å°æ—¶ï¼‰...")
    print("=" * 70)

    # å¦‚æžœæ˜¯ç»­ä¼ æ¨¡å¼ï¼Œè¯»å–å·²å¤„ç†çš„åŸºé‡‘ä»£ç 
    processed_symbols = set()
    if resume:
        print("\nðŸ”„ æ–­ç‚¹ç»­ä¼ æ¨¡å¼")
        processed_symbols = load_processed_symbols(output_file)
        if processed_symbols:
            print(f"   å·²å¤„ç† {len(processed_symbols)} ä¸ªåŸºé‡‘ï¼Œå°†è·³è¿‡è¿™äº›åŸºé‡‘")
        else:
            print("   æœªæ‰¾åˆ°å·²å¤„ç†è®°å½•ï¼Œä»Žå¤´å¼€å§‹")

    print("\n[1/3] æ­£åœ¨å¯åŠ¨æµè§ˆå™¨...")
    browser_manager = BrowserManager(headless=True)

    try:
        await browser_manager.start()
        print("âœ… æµè§ˆå™¨å¯åŠ¨æˆåŠŸ")

        print("\n[2/3] æ­£åœ¨åˆå§‹åŒ–çˆ¬è™«...")
        scraper = EastmoneyScraper(browser_manager)
        print("âœ… çˆ¬è™«åˆå§‹åŒ–å®Œæˆ")

        print("\n[3/3] æ­£åœ¨èŽ·å–åŸºé‡‘æ•°æ®...")

        # èŽ·å–åŸºé‡‘ä»£ç åˆ—è¡¨
        print("  [æ­¥éª¤1] æ­£åœ¨èŽ·å–åŸºé‡‘ä»£ç åˆ—è¡¨...")
        print("    æ­£åœ¨è®¿é—®åŸºé‡‘ä»£ç æ•°æ®é¡µé¢...")
        codes_result = await scraper.scrape_all_fund_codes()

        if not codes_result['success']:
            print(f"âŒ èŽ·å–åŸºé‡‘ä»£ç åˆ—è¡¨å¤±è´¥")
            return None

        all_codes = codes_result['data']
        print(f"  âœ… æˆåŠŸèŽ·å– {len(all_codes)} ä¸ªåŸºé‡‘ä»£ç ")

        # é™åˆ¶æ•°é‡ï¼ˆå¦‚æžœæŒ‡å®šï¼‰
        if max_funds:
            all_codes = all_codes[:max_funds]
            print(f"  â„¹ï¸  é™åˆ¶ä¸ºå‰ {max_funds} ä¸ªåŸºé‡‘")

        total = len(all_codes)

        # è¿‡æ»¤å·²å¤„ç†çš„åŸºé‡‘
        todo_codes = [f for f in all_codes if f['symbol'] not in processed_symbols]
        skipped = len(all_codes) - len(todo_codes)

        if skipped > 0:
            print(f"  â„¹ï¸  è·³è¿‡å·²å¤„ç†çš„ {skipped} ä¸ªåŸºé‡‘")
            print(f"  â„¹ï¸  è¿˜éœ€å¤„ç† {len(todo_codes)} ä¸ªåŸºé‡‘")

        # å¼€å§‹å¢žé‡å†™å…¥
        print(f"\n  [æ­¥éª¤2] å¼€å§‹æ‰¹é‡èŽ·å–åŸºé‡‘è¯¦æƒ…ï¼ˆæ¯æ‰¹ {batch_size} ä¸ªï¼Œå»¶è¿Ÿ {delay}ç§’ï¼‰...")
        print(f"  ðŸ’¾ æ•°æ®å°†å®žæ—¶å†™å…¥æ–‡ä»¶: {os.path.abspath(output_file)}\n")

        success_count = 0
        failed_count = 0
        failed_symbols = []

        with IncrementalCSVWriter(output_file) as csv_writer:
            for i in range(0, len(todo_codes), batch_size):
                batch = todo_codes[i:i+batch_size]
                batch_symbols = [f['symbol'] for f in batch]

                batch_num = i // batch_size + 1
                total_batches = (len(todo_codes) + batch_size - 1) // batch_size
                print(f"  ã€æ‰¹æ¬¡ {batch_num}/{total_batches}ã€‘ æ­£åœ¨èŽ·å–ç¬¬ {i+1}-{min(i+batch_size, len(todo_codes))} ä¸ªåŸºé‡‘...")

                batch_success = 0
                for idx, symbol in enumerate(batch_symbols, 1):
                    try:
                        # æ˜¾ç¤ºå½“å‰è¿›åº¦
                        current = i + idx
                        overall = skipped + current
                        print(f"    [{overall}/{total}] {symbol}...", end='', flush=True)

                        result = await scraper.scrape_detail(symbol)
                        if result['success']:
                            fund_data = result['data']

                            # æ ¼å¼åŒ–ä¸ºä¸Žæ—§ä»£ç å…¼å®¹çš„å­—æ®µå
                            formatted_data = {
                                'symbol': fund_data.get('symbol', ''),
                                'sname': fund_data.get('sname', ''),
                                'per_nav': fund_data.get('per_nav', ''),
                                'total_nav': fund_data.get('total_nav', ''),
                                'yesterday_nav': fund_data.get('yesterday_nav', ''),
                                'nav_rate': fund_data.get('nav_rate', ''),
                                'nav_a': fund_data.get('nav_a', ''),
                                'sg_states': fund_data.get('sg_states', ''),
                                'nav_date': fund_data.get('nav_date', ''),
                                'fund_manager': fund_data.get('fund_manager', ''),
                                'jjlx': fund_data.get('jjlx', ''),
                                'jjzfe': fund_data.get('fund_scale', '')  # fund_scale -> jjzfe
                            }

                            # ç«‹å³å†™å…¥æ–‡ä»¶
                            csv_writer.write(formatted_data)
                            success_count += 1
                            batch_success += 1
                            print(" âœ…")
                        else:
                            failed_count += 1
                            failed_symbols.append(symbol)
                            print(" âŒ")
                    except Exception as e:
                        print(f" âŒ é”™è¯¯: {str(e)[:50]}")
                        failed_count += 1
                        failed_symbols.append(symbol)

                    # å»¶è¿Ÿ
                    await scraper.random_delay(delay * 0.8, delay * 1.2)

                # æ‰¹æ¬¡å®Œæˆç»Ÿè®¡
                print(f"  æ‰¹æ¬¡å®Œæˆ: æˆåŠŸ {batch_success}/{len(batch_symbols)} ä¸ª")
                print(f"  æ€»è¿›åº¦: æˆåŠŸ {success_count + skipped}/{total} (æœ¬æ¬¡æ–°å¢ž {success_count})\n")

        # è¿”å›žç»Ÿè®¡ä¿¡æ¯
        return {
            'success': True,
            'total_count': success_count + skipped,
            'new_count': success_count,
            'skipped_count': skipped,
            'failed_count': failed_count,
            'failed_symbols': failed_symbols[:100] if len(failed_symbols) > 100 else failed_symbols
        }

    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

    finally:
        await browser_manager.close()


def main():
    parser = argparse.ArgumentParser(
        description='èŽ·å–åŸºé‡‘æ•°æ®ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python fetch_funds.py --max 100                    # èŽ·å–å‰100ä¸ªåŸºé‡‘
  python fetch_funds.py --all                        # èŽ·å–æ‰€æœ‰åŸºé‡‘
  python fetch_funds.py --max 500 --output my.csv    # æŒ‡å®šæ–‡ä»¶å
  python fetch_funds.py --all --resume               # æ–­ç‚¹ç»­ä¼ 
  python fetch_funds.py --all --batch 200 --delay 0.5  # è‡ªå®šä¹‰æ‰¹æ¬¡å¤§å°å’Œå»¶è¿Ÿ
        """
    )

    parser.add_argument('--max', type=int, help='èŽ·å–çš„æœ€å¤§åŸºé‡‘æ•°é‡')
    parser.add_argument('--all', action='store_true', help='èŽ·å–æ‰€æœ‰åŸºé‡‘ï¼ˆçº¦26000+ä¸ªï¼‰')
    parser.add_argument('--output', '-o', help='è¾“å‡ºæ–‡ä»¶åï¼ˆé»˜è®¤è‡ªåŠ¨ç”Ÿæˆï¼‰')
    parser.add_argument('--resume', action='store_true', help='æ–­ç‚¹ç»­ä¼ æ¨¡å¼ï¼ˆä»Žå·²æœ‰æ–‡ä»¶ç»§ç»­ï¼‰')
    parser.add_argument('--batch', type=int, default=100,
                        help='æ¯æ‰¹èŽ·å–çš„åŸºé‡‘æ•°é‡ (é»˜è®¤: 100)')
    parser.add_argument('--delay', type=float, default=1.0,
                        help='æ¯æ‰¹ä¹‹é—´çš„å»¶è¿Ÿç§’æ•° (é»˜è®¤: 1.0)')

    args = parser.parse_args()

    # ç¡®å®šèŽ·å–æ•°é‡
    if args.all:
        max_funds = None
    elif args.max:
        max_funds = args.max
    else:
        # é»˜è®¤èŽ·å–100ä¸ª
        max_funds = 100
        print(f"æœªæŒ‡å®šæ•°é‡ï¼Œé»˜è®¤èŽ·å–å‰ {max_funds} ä¸ªåŸºé‡‘")
        print("æç¤º: ä½¿ç”¨ --max N æŒ‡å®šæ•°é‡ï¼Œæˆ– --all èŽ·å–å…¨éƒ¨\n")

    # ç¡®å®šè¾“å‡ºæ–‡ä»¶å
    if args.output:
        output_file = args.output
    else:
        if args.resume:
            # ç»­ä¼ æ¨¡å¼éœ€è¦æŒ‡å®šæ–‡ä»¶
            print("âŒ é”™è¯¯: æ–­ç‚¹ç»­ä¼ æ¨¡å¼å¿…é¡»ä½¿ç”¨ --output æŒ‡å®šæ–‡ä»¶å")
            sys.exit(1)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_file = f'funds_data_{timestamp}.csv'

    # èŽ·å–æ•°æ®ï¼ˆå¢žé‡æ¨¡å¼ï¼‰
    result = asyncio.run(fetch_funds_incremental(
        output_file=output_file,
        max_funds=max_funds,
        batch_size=args.batch,
        delay=args.delay,
        resume=args.resume
    ))

    if not result:
        sys.exit(1)

    # æ˜¾ç¤ºç»Ÿè®¡
    abs_path = os.path.abspath(output_file)
    print(f"\n" + "=" * 70)
    print(f"æ•°æ®èŽ·å–å®Œæˆ")
    print(f"=" * 70)
    print(f"âœ… æ–‡ä»¶ä½ç½®: {abs_path}")
    print(f"âœ… æ€»è®°å½•æ•°: {result.get('total_count', 0)} ä¸ª")
    if result.get('skipped_count', 0) > 0:
        print(f"   - å·²æœ‰è®°å½•: {result.get('skipped_count', 0)} ä¸ª")
        print(f"   - æ–°å¢žè®°å½•: {result.get('new_count', 0)} ä¸ª")
    print(f"âŒ å¤±è´¥: {result.get('failed_count', 0)} ä¸ª")
    if result.get('failed_symbols'):
        print(f"   å¤±è´¥çš„åŸºé‡‘ä»£ç : {', '.join(result['failed_symbols'][:10])}")
        if len(result['failed_symbols']) > 10:
            print(f"   ... è¿˜æœ‰ {len(result['failed_symbols']) - 10} ä¸ª")


if __name__ == "__main__":
    main()
